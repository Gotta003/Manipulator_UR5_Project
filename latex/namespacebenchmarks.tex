\doxysection{benchmarks Namespace Reference}
\hypertarget{namespacebenchmarks}{}\label{namespacebenchmarks}\index{benchmarks@{benchmarks}}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacebenchmarks_ade05a8dbc202c6aacb5761e8e4c5ea5e}{run}} (weights=\mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}/"{}yolov5s.\+pt"{}, imgsz=640, batch\+\_\+size=1, data=\mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}/"{}data/coco128.\+yaml"{}, device="{}"{}, half=False, \mbox{\hyperlink{namespacebenchmarks_a64ada08bd2cbc822a6f715b7ee100cdf}{test}}=False, pt\+\_\+only=False, hard\+\_\+fail=False)
\item 
\mbox{\hyperlink{namespacebenchmarks_a64ada08bd2cbc822a6f715b7ee100cdf}{test}} (weights=\mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}/"{}yolov5s.\+pt"{}, imgsz=640, batch\+\_\+size=1, data=\mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}/"{}data/coco128.\+yaml"{}, device="{}"{}, half=False, test=False, pt\+\_\+only=False, hard\+\_\+fail=False)
\item 
\mbox{\hyperlink{namespacebenchmarks_a0d5f1198ff50977ed087410f1e961b21}{parse\+\_\+opt}} ()
\item 
\mbox{\hyperlink{namespacebenchmarks_a88da04a12f0c6fa3141393e587ee79f7}{main}} (\mbox{\hyperlink{namespacebenchmarks_a110ebb765dff3038f95f6c95bd7c63f7}{opt}})
\end{DoxyCompactItemize}
\doxysubsubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacebenchmarks_aec626caa437b94fbcaa05390e9771510}{FILE}} = Path(\+\_\+\+\_\+file\+\_\+\+\_\+).resolve()
\item 
\mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}} = FILE.\+parents\mbox{[}0\mbox{]}
\item 
\mbox{\hyperlink{namespacebenchmarks_a110ebb765dff3038f95f6c95bd7c63f7}{opt}} = \mbox{\hyperlink{namespacebenchmarks_a0d5f1198ff50977ed087410f1e961b21}{parse\+\_\+opt}}()
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Run YOLOv5 benchmarks on all supported export formats.

Format                      | `export.py --include`         | Model
---                         | ---                           | ---
PyTorch                     | -                             | yolov5s.pt
TorchScript                 | `torchscript`                 | yolov5s.torchscript
ONNX                        | `onnx`                        | yolov5s.onnx
OpenVINO                    | `openvino`                    | yolov5s_openvino_model/
TensorRT                    | `engine`                      | yolov5s.engine
CoreML                      | `coreml`                      | yolov5s.mlpackage
TensorFlow SavedModel       | `saved_model`                 | yolov5s_saved_model/
TensorFlow GraphDef         | `pb`                          | yolov5s.pb
TensorFlow Lite             | `tflite`                      | yolov5s.tflite
TensorFlow Edge TPU         | `edgetpu`                     | yolov5s_edgetpu.tflite
TensorFlow.js               | `tfjs`                        | yolov5s_web_model/

Requirements:
    $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu  # CPU
    $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow  # GPU
    $ pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # TensorRT

Usage:
    $ python benchmarks.py --weights yolov5s.pt --img 640
\end{DoxyVerb}
 

\doxysubsection{Function Documentation}
\Hypertarget{namespacebenchmarks_a88da04a12f0c6fa3141393e587ee79f7}\index{benchmarks@{benchmarks}!main@{main}}
\index{main@{main}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{main()}{main()}}
{\footnotesize\ttfamily \label{namespacebenchmarks_a88da04a12f0c6fa3141393e587ee79f7} 
benchmarks.\+main (\begin{DoxyParamCaption}\item[{}]{opt}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Executes YOLOv5 benchmark tests or main training/inference routines based on the provided command-line arguments.

Args:
    opt (argparse.Namespace): Parsed command-line arguments including options for weights, image size, batch size, data
        configuration, device, and other flags for inference settings.

Returns:
    None: This function does not return any value. It leverages side-effects such as logging and running benchmarks.

Example:
    ```python
    if __name__ == "__main__":
        opt = parse_opt()
        main(opt)
    ```

Notes:
    - For a complete list of supported export formats and their respective requirements, refer to the
      [Ultralytics YOLOv5 Export Formats](https://github.com/ultralytics/yolov5#export-formats).
    - Ensure that you have installed all necessary dependencies by following the installation instructions detailed in
      the [main repository](https://github.com/ultralytics/yolov5#installation).

    ```shell
    # Running benchmarks on default weights and image size
    $ python benchmarks.py --weights yolov5s.pt --img 640
    ```
\end{DoxyVerb}
 \Hypertarget{namespacebenchmarks_a0d5f1198ff50977ed087410f1e961b21}\index{benchmarks@{benchmarks}!parse\_opt@{parse\_opt}}
\index{parse\_opt@{parse\_opt}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{parse\_opt()}{parse\_opt()}}
{\footnotesize\ttfamily \label{namespacebenchmarks_a0d5f1198ff50977ed087410f1e961b21} 
benchmarks.\+parse\+\_\+opt (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Parses command-line arguments for YOLOv5 model inference configuration.

Args:
    weights (str): The path to the weights file. Defaults to 'ROOT / "yolov5s.pt"'.
    imgsz (int): Inference size in pixels. Defaults to 640.
    batch_size (int): Batch size. Defaults to 1.
    data (str): Path to the dataset YAML file. Defaults to 'ROOT / "data/coco128.yaml"'.
    device (str): CUDA device, e.g., '0' or '0,1,2,3' or 'cpu'. Defaults to an empty string (auto-select).
    half (bool): Use FP16 half-precision inference. This is a flag and defaults to False.
    test (bool): Test exports only. This is a flag and defaults to False.
    pt_only (bool): Test PyTorch only. This is a flag and defaults to False.
    hard_fail (bool | str): Throw an error on benchmark failure. Can be a boolean or a string representing a minimum
        metric floor, e.g., '0.29'. Defaults to False.

Returns:
    argparse.Namespace: Parsed command-line arguments encapsulated in an argparse Namespace object.

Notes:
    The function modifies the 'opt.data' by checking and validating the YAML path using 'check_yaml()'.
    The parsed arguments are printed for reference using 'print_args()'.
\end{DoxyVerb}
 \Hypertarget{namespacebenchmarks_ade05a8dbc202c6aacb5761e8e4c5ea5e}\index{benchmarks@{benchmarks}!run@{run}}
\index{run@{run}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{run()}{run()}}
{\footnotesize\ttfamily \label{namespacebenchmarks_ade05a8dbc202c6aacb5761e8e4c5ea5e} 
benchmarks.\+run (\begin{DoxyParamCaption}\item[{}]{weights}{ = {\ttfamily \mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}~/~"{}yolov5s.pt"{}}, }\item[{}]{imgsz}{ = {\ttfamily 640}, }\item[{}]{batch\+\_\+size}{ = {\ttfamily 1}, }\item[{}]{data}{ = {\ttfamily \mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}~/~"{}data/coco128.yaml"{}}, }\item[{}]{device}{ = {\ttfamily "{}"{}}, }\item[{}]{half}{ = {\ttfamily False}, }\item[{}]{test}{ = {\ttfamily False}, }\item[{}]{pt\+\_\+only}{ = {\ttfamily False}, }\item[{}]{hard\+\_\+fail}{ = {\ttfamily False}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Run YOLOv5 benchmarks on multiple export formats and log results for model performance evaluation.

Args:
    weights (Path | str): Path to the model weights file (default: ROOT / "yolov5s.pt").
    imgsz (int): Inference size in pixels (default: 640).
    batch_size (int): Batch size for inference (default: 1).
    data (Path | str): Path to the dataset.yaml file (default: ROOT / "data/coco128.yaml").
    device (str): CUDA device, e.g., '0' or '0,1,2,3' or 'cpu' (default: "").
    half (bool): Use FP16 half-precision inference (default: False).
    test (bool): Test export formats only (default: False).
    pt_only (bool): Test PyTorch format only (default: False).
    hard_fail (bool): Throw an error on benchmark failure if True (default: False).

Returns:
    None. Logs information about the benchmark results, including the format, size, mAP50-95, and inference time.

Notes:
    Supported export formats and models include PyTorch, TorchScript, ONNX, OpenVINO, TensorRT, CoreML,
        TensorFlow SavedModel, TensorFlow GraphDef, TensorFlow Lite, and TensorFlow Edge TPU. Edge TPU and TF.js
        are unsupported.

Example:
    ```python
    $ python benchmarks.py --weights yolov5s.pt --img 640
    ```

Usage:
    Install required packages:
      $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu  # CPU support
      $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow   # GPU support
      $ pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # TensorRT

    Run benchmarks:
      $ python benchmarks.py --weights yolov5s.pt --img 640
\end{DoxyVerb}
 \Hypertarget{namespacebenchmarks_a64ada08bd2cbc822a6f715b7ee100cdf}\index{benchmarks@{benchmarks}!test@{test}}
\index{test@{test}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{test()}{test()}}
{\footnotesize\ttfamily \label{namespacebenchmarks_a64ada08bd2cbc822a6f715b7ee100cdf} 
benchmarks.\+test (\begin{DoxyParamCaption}\item[{}]{weights}{ = {\ttfamily \mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}~/~"{}yolov5s.pt"{}}, }\item[{}]{imgsz}{ = {\ttfamily 640}, }\item[{}]{batch\+\_\+size}{ = {\ttfamily 1}, }\item[{}]{data}{ = {\ttfamily \mbox{\hyperlink{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}{ROOT}}~/~"{}data/coco128.yaml"{}}, }\item[{}]{device}{ = {\ttfamily "{}"{}}, }\item[{}]{half}{ = {\ttfamily False}, }\item[{}]{test}{ = {\ttfamily False}, }\item[{}]{pt\+\_\+only}{ = {\ttfamily False}, }\item[{}]{hard\+\_\+fail}{ = {\ttfamily False}}\end{DoxyParamCaption})}

\begin{DoxyVerb}Run YOLOv5 export tests for all supported formats and log the results, including export statuses.

Args:
    weights (Path | str): Path to the model weights file (.pt format). Default is 'ROOT / "yolov5s.pt"'.
    imgsz (int): Inference image size (in pixels). Default is 640.
    batch_size (int): Batch size for testing. Default is 1.
    data (Path | str): Path to the dataset configuration file (.yaml format). Default is 'ROOT / "data/coco128.yaml"'.
    device (str): Device for running the tests, can be 'cpu' or a specific CUDA device ('0', '0,1,2,3', etc.). Default is an empty string.
    half (bool): Use FP16 half-precision for inference if True. Default is False.
    test (bool): Test export formats only without running inference. Default is False.
    pt_only (bool): Test only the PyTorch model if True. Default is False.
    hard_fail (bool): Raise error on export or test failure if True. Default is False.

Returns:
    pd.DataFrame: DataFrame containing the results of the export tests, including format names and export statuses.

Examples:
    ```python
    $ python benchmarks.py --weights yolov5s.pt --img 640
    ```

Notes:
    Supported export formats and models include PyTorch, TorchScript, ONNX, OpenVINO, TensorRT, CoreML, TensorFlow
    SavedModel, TensorFlow GraphDef, TensorFlow Lite, and TensorFlow Edge TPU. Edge TPU and TF.js are unsupported.

Usage:
    Install required packages:
        $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu  # CPU support
        $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow   # GPU support
        $ pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # TensorRT
    Run export tests:
        $ python benchmarks.py --weights yolov5s.pt --img 640
\end{DoxyVerb}
 

\doxysubsection{Variable Documentation}
\Hypertarget{namespacebenchmarks_aec626caa437b94fbcaa05390e9771510}\index{benchmarks@{benchmarks}!FILE@{FILE}}
\index{FILE@{FILE}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{FILE}{FILE}}
{\footnotesize\ttfamily \label{namespacebenchmarks_aec626caa437b94fbcaa05390e9771510} 
benchmarks.\+FILE = Path(\+\_\+\+\_\+file\+\_\+\+\_\+).resolve()}

\Hypertarget{namespacebenchmarks_a110ebb765dff3038f95f6c95bd7c63f7}\index{benchmarks@{benchmarks}!opt@{opt}}
\index{opt@{opt}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{opt}{opt}}
{\footnotesize\ttfamily \label{namespacebenchmarks_a110ebb765dff3038f95f6c95bd7c63f7} 
benchmarks.\+opt = \mbox{\hyperlink{namespacebenchmarks_a0d5f1198ff50977ed087410f1e961b21}{parse\+\_\+opt}}()}

\Hypertarget{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6}\index{benchmarks@{benchmarks}!ROOT@{ROOT}}
\index{ROOT@{ROOT}!benchmarks@{benchmarks}}
\doxysubsubsection{\texorpdfstring{ROOT}{ROOT}}
{\footnotesize\ttfamily \label{namespacebenchmarks_a783652233b34d5ee8aa4e4eb2304cbd6} 
benchmarks.\+ROOT = FILE.\+parents\mbox{[}0\mbox{]}}

