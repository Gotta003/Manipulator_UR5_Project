\doxysection{models.\+common.\+Transformer\+Layer Class Reference}
\hypertarget{classmodels_1_1common_1_1_transformer_layer}{}\label{classmodels_1_1common_1_1_transformer_layer}\index{models.common.TransformerLayer@{models.common.TransformerLayer}}
Inheritance diagram for models.\+common.\+Transformer\+Layer\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classmodels_1_1common_1_1_transformer_layer}
\end{center}
\end{figure}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a49a84ef11ce4aa6281433a1da45cbeac}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, c, num\+\_\+heads)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a8237bf1aaab7a9a2c6d809cf66862270}{forward}} (self, x)
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a489707f5df93ca5643e3d081777604cf}{q}} = nn.\+Linear(c, c, bias=False)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a41fc3e36868f22924a6dbf2718e7093c}{k}} = nn.\+Linear(c, c, bias=False)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a7f976d5cb189571fcffe97b7e099304c}{v}} = nn.\+Linear(c, c, bias=False)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a9caca012a8ba59435d57834f176e7234}{ma}} = nn.\+Multihead\+Attention(embed\+\_\+dim=c, num\+\_\+heads=num\+\_\+heads)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_ac55f67c862fe19a5920f4e19bfc25fb7}{fc1}} = nn.\+Linear(c, c, bias=False)
\item 
\mbox{\hyperlink{classmodels_1_1common_1_1_transformer_layer_a43b3a9c7c3b9efb07d6b35045089a017}{fc2}} = nn.\+Linear(c, c, bias=False)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Transformer layer with multihead attention and linear layers, optimized by removing LayerNorm.\end{DoxyVerb}
 

\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a49a84ef11ce4aa6281433a1da45cbeac}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a49a84ef11ce4aa6281433a1da45cbeac} 
models.\+common.\+Transformer\+Layer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{c}{, }\item[{}]{num\+\_\+heads}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Initializes a transformer layer, sans LayerNorm for performance, with multihead attention and linear layers.

See  as described in https://arxiv.org/abs/2010.11929.
\end{DoxyVerb}
 

\doxysubsection{Member Function Documentation}
\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a8237bf1aaab7a9a2c6d809cf66862270}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!forward@{forward}}
\index{forward@{forward}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a8237bf1aaab7a9a2c6d809cf66862270} 
models.\+common.\+Transformer\+Layer.\+forward (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{x}{}\end{DoxyParamCaption})}

\begin{DoxyVerb}Performs forward pass using MultiheadAttention and two linear transformations with residual connections.\end{DoxyVerb}
 

\doxysubsection{Member Data Documentation}
\Hypertarget{classmodels_1_1common_1_1_transformer_layer_ac55f67c862fe19a5920f4e19bfc25fb7}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!fc1@{fc1}}
\index{fc1@{fc1}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{fc1}{fc1}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_ac55f67c862fe19a5920f4e19bfc25fb7} 
models.\+common.\+Transformer\+Layer.\+fc1 = nn.\+Linear(c, c, bias=False)}

\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a43b3a9c7c3b9efb07d6b35045089a017}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!fc2@{fc2}}
\index{fc2@{fc2}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{fc2}{fc2}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a43b3a9c7c3b9efb07d6b35045089a017} 
models.\+common.\+Transformer\+Layer.\+fc2 = nn.\+Linear(c, c, bias=False)}

\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a41fc3e36868f22924a6dbf2718e7093c}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!k@{k}}
\index{k@{k}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{k}{k}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a41fc3e36868f22924a6dbf2718e7093c} 
models.\+common.\+Transformer\+Layer.\+k = nn.\+Linear(c, c, bias=False)}

\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a9caca012a8ba59435d57834f176e7234}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!ma@{ma}}
\index{ma@{ma}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{ma}{ma}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a9caca012a8ba59435d57834f176e7234} 
models.\+common.\+Transformer\+Layer.\+ma = nn.\+Multihead\+Attention(embed\+\_\+dim=c, num\+\_\+heads=num\+\_\+heads)}

\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a489707f5df93ca5643e3d081777604cf}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!q@{q}}
\index{q@{q}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{q}{q}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a489707f5df93ca5643e3d081777604cf} 
models.\+common.\+Transformer\+Layer.\+q = nn.\+Linear(c, c, bias=False)}

\Hypertarget{classmodels_1_1common_1_1_transformer_layer_a7f976d5cb189571fcffe97b7e099304c}\index{models.common.TransformerLayer@{models.common.TransformerLayer}!v@{v}}
\index{v@{v}!models.common.TransformerLayer@{models.common.TransformerLayer}}
\doxysubsubsection{\texorpdfstring{v}{v}}
{\footnotesize\ttfamily \label{classmodels_1_1common_1_1_transformer_layer_a7f976d5cb189571fcffe97b7e099304c} 
models.\+common.\+Transformer\+Layer.\+v = nn.\+Linear(c, c, bias=False)}



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
robotics\+\_\+project\+\_\+ws/src/vision\+\_\+ws/yolov5/models/\mbox{\hyperlink{common_8py}{common.\+py}}\end{DoxyCompactItemize}
